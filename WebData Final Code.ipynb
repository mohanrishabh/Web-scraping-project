{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": true,
    "editable": true
   },
   "source": [
    "# Scraping 10-K Urls from Edgar"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "pwd\n",
    "import os\n",
    "os.chdir(\"C:\\\\Users\\\\Rishabhmohan\\\\desktop\\\\course\\\\2017FALL\\\\Web Data Analytics\\\\Group Projects\")\n",
    "\n",
    "import pandas as pd\n",
    "import urllib2\n",
    "import bs4 as bs\n",
    "from bs4 import SoupStrainer\n",
    "\n",
    "weblink = []\n",
    "weblink1 = []\n",
    "filing_type = []\n",
    "company_name = []\n",
    "ticker=[]\n",
    "date = [] \n",
    "df = pd.read_csv('all companies.csv')   #companies list collated from the internet\n",
    "\n",
    "Symbol=list(df['Symbol'])\n",
    "Name=list(df['Name'])\n",
    "\n",
    "from urllib import FancyURLopener  # This is library that helps us create the headless browser\n",
    "from random import choice #This library helps pick a random item from a list\n",
    "user_agents = [\n",
    "    'Mozilla/5.0 (Windows NT 6.1) AppleWebKit/537.36 (KHTML, like Gecko) Chrome/41.0.2228.0 Safari/537.36',\n",
    "    'Opera/9.80 (X11; Linux i686; Ubuntu/14.10) Presto/2.12.388 Version/12.16',\n",
    "    'Mozilla/5.0 (Windows; U; Windows NT 6.1; rv:2.2) Gecko/20110201',\n",
    "    'Mozilla/5.0 (Macintosh; Intel Mac OS X 10_9_3) AppleWebKit/537.75.14 (KHTML, like Gecko) Version/7.0.3 Safari/7046A194A',\n",
    "    'Mozilla/5.0 (Windows NT 10.0; Win64; x64) AppleWebKit/537.36 (KHTML, like Gecko) Chrome/42.0.2311.135 Safari/537.36 Edge/12.246'\n",
    "]\n",
    "link=[]\n",
    "for item in range(0,len(Symbol)):\n",
    "        link ='https://www.sec.gov/cgi-bin/browse-edgar?action=getcompany&CIK=' + Symbol[item] + '&type=10-K&dateb=&owner=exclude&count=40'\n",
    "        class MyOpener(FancyURLopener, object):\n",
    "                version = choice(user_agents)\n",
    "        \n",
    "        myopener = MyOpener()\n",
    "        page=myopener.open(link)\n",
    "        \n",
    "        html = page.read()\n",
    "        soup =bs.BeautifulSoup(html,\"lxml\")\n",
    "        infotable = soup.find_all(\"table\",class_ = \"tableFile2\")\n",
    "        if html.find('nowrap') != -1:\n",
    "            if infotable != []:\n",
    "                rows = infotable[0].find_all('tr')\n",
    "                for i in rows[1:]:\n",
    "                    columns = i.find_all('td')\n",
    "                    filing_type.append(columns[0].getText())\n",
    "                    templink=columns[1].find(\"a\",href=True)\n",
    "                    weblink.append(\"https://www.sec.gov\"+templink['href'])\n",
    "                    date.append(columns[3].getText())\n",
    "                    ticker.append(Symbol[item])\n",
    "                    company_name.append(Name[item])\n",
    "        elif infotable==[]:\n",
    "            continue\n",
    "\n",
    "for y in weblink:\n",
    "            myopener2 = MyOpener()\n",
    "            page1=myopener2.open(y)\n",
    "            html3 = page1.read()\n",
    "            soup2 =bs.BeautifulSoup(html3,\"lxml\")\n",
    "            infotable1 = soup2.find_all(\"table\",class_ = \"tableFile\")\n",
    "            rows1 = infotable1[0].find_all('tr')\n",
    "        \n",
    "            for i in rows1[1:2]:\n",
    "                columns1 = i.find_all('td')                             \n",
    "                templink1=columns1[2].find(\"a\",href=True)\n",
    "                weblink1.append(\"https://www.sec.gov\"+templink1['href'])\n",
    "                                     \n",
    "\n",
    "sum_list=[]\n",
    "sum_list.append(['Symbol','Company Name','Date of Filing','Filing Type','Link of Document'])\n",
    "for i in range(0,len(weblink1)):\n",
    "    if filing_type[i]!=\"10-K\":\n",
    "        continue\n",
    "    if date[i]<'2013-01-01':\n",
    "        continue\n",
    "    sum_list.append([ticker[i],company_name[i],date[i],filing_type[i],weblink1[i]])\n",
    "import csv\n",
    "with open('C:\\\\Users\\\\WEILUN\\\\desktop\\\\course\\\\2017FALL\\\\Web Data Analytics\\\\Group Projects\\\\10K links(soup).csv','wb') as f:\n",
    "    writer=csv.writer(f)\n",
    "    writer.writerows(sum_list)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": true,
    "editable": true
   },
   "source": [
    "# Reading Used words from the links"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "import os\n",
    "os.chdir(\"C:\\Users\\User\\Desktop\\Web Data Analytics\\Project\\WorkDir\")\n",
    "import pandas as pd\n",
    "import urllib2\n",
    "import bs4 as bs\n",
    "from bs4 import SoupStrainer\n",
    "df = pd.read_csv('10Klinks_final.csv')\n",
    "df['BigData1']=0\n",
    "df['BigData2']=0\n",
    "df['Cloud']=0\n",
    "df['AI']=0\n",
    "df['ML']=0\n",
    "df['Analytics']=0\n",
    "\n",
    "df['Autonomous vehicles']=0\n",
    "df['Robotics']=0\n",
    "df['Augmented Reality']=0\n",
    "df['Virtual Reality']=0\n",
    "df['D3_Printing']=0\n",
    "df['Drones']=0\n",
    "df['Internet of Things']=0\n",
    "df['Blockchain']=0\n",
    "df['Nanotechnology']=0\n",
    "df['Nano technology']=0\n",
    "df['Quantum_Computing']=0\n",
    "\n",
    "\n",
    "bigdata_list1=[]\n",
    "bigdata_list2=[]\n",
    "cloud_list=[]\n",
    "AI_list=[]\n",
    "ML_list=[]\n",
    "Analytics_list=[]\n",
    "\n",
    "Autonomous_vehicles_list=[]\n",
    "Robotics_list=[]\n",
    "Augmented_Reality_list=[]\n",
    "Virtual_Reality_list=[]\n",
    "D3_Printing_list=[]\n",
    "Drones_list=[]\n",
    "Internet_of_Things_list=[]\n",
    "Blockchain_list=[]\n",
    "Nanotechnology_list=[]\n",
    "Quantum_Computing_list=[]\n",
    "\n",
    "for link in df['Link of Document']:\n",
    "# link = 'https://www.sec.gov/Archives/edgar/data/353184/000035318414000011/airt10k_033114.htm'\n",
    "    html = urllib2.urlopen(link).read()\n",
    "    import re\n",
    "    list1=[]\n",
    "    wordlist=['big data','bigdata','cloud computing','artificial intelligence','machine learning','Analytics',\n",
    "             'Autonomous_vehicles',\n",
    "'Robotics',\n",
    "'Augmented_Reality',\n",
    "'Virtual_Reality',\n",
    "'3D Printing',\n",
    "'Drones',\n",
    "'Internet_of_Things',\n",
    "'Blockchain',\n",
    "'Nanotechnology',\n",
    "'Quantum_Computing'\n",
    "]\n",
    "#     wordlist=['data','computing','artificial intelligence','machine learning','kjkjh']\n",
    "    for word in wordlist:\n",
    "        keyword_count=len(re.findall(word,html,re.IGNORECASE))\n",
    "        if keyword_count>0:\n",
    "            list1.append(keyword_count)\n",
    "        else:\n",
    "            list1.append(0)\n",
    "    if list1[0]>0:\n",
    "        bigdata_list1.append(list1[0])\n",
    "    if list1[0]==0:\n",
    "        bigdata_list1.append(0)\n",
    "        \n",
    "    if list1[1]>0:\n",
    "        bigdata_list2.append(list1[1])\n",
    "    if list1[1]==0:\n",
    "        bigdata_list2.append(0)\n",
    "        \n",
    "    if list1[2]>0:\n",
    "        cloud_list.append(list1[2])\n",
    "    if list1[2]==0:\n",
    "        cloud_list.append(0)\n",
    "\n",
    "    if list1[3]>0:\n",
    "        AI_list.append(list1[3])\n",
    "    if list1[3]==0:\n",
    "        AI_list.append(0)\n",
    "\n",
    "    if list1[4]>0:\n",
    "        ML_list.append(list1[4])\n",
    "    if list1[4]==0:\n",
    "        ML_list.append(0)\n",
    "        \n",
    "    if list1[5]>0:\n",
    "        Analytics_list.append(list1[5])\n",
    "    if list1[5]==0:\n",
    "        Analytics_list.append(0)\n",
    "        \n",
    "    if list1[6]>0:\n",
    "        Autonomous_vehicles_list.append(list1[5])\n",
    "    if list1[6]==0:\n",
    "        Autonomous_vehicles_list.append(0)\n",
    "    if list1[7]>0:\n",
    "        Robotics_list.append(list1[1])\n",
    "    if list1[7]==0:\n",
    "        Robotics_list.append(0)\n",
    "        \n",
    "    if list1[8]>0:\n",
    "        Augmented_Reality_list.append(list1[2])\n",
    "    if list1[8]==0:\n",
    "        Augmented_Reality_list.append(0)\n",
    "\n",
    "    if list1[9]>0:\n",
    "        Virtual_Reality_list.append(list1[3])\n",
    "    if list1[9]==0:\n",
    "        Virtual_Reality_list.append(0)\n",
    "\n",
    "    if list1[10]>0:\n",
    "        D3_Printing_list.append(list1[4])\n",
    "    if list1[10]==0:\n",
    "        D3_Printing_list.append(0)\n",
    "        \n",
    "    if list1[11]>0:\n",
    "        Drones_list.append(list1[5])\n",
    "    if list1[11]==0:\n",
    "        Drones_list.append(0)\n",
    "    if list1[12]>0:\n",
    "        Internet_of_Things_list.append(list1[1])\n",
    "    if list1[12]==0:\n",
    "        Internet_of_Things_list.append(0)\n",
    "        \n",
    "    if list1[13]>0:\n",
    "        Blockchain_list.append(list1[2])\n",
    "    if list1[13]==0:\n",
    "        Blockchain_list.append(0)\n",
    "\n",
    "    if list1[14]>0:\n",
    "        Nanotechnology_list.append(list1[3])\n",
    "    if list1[14]==0:\n",
    "        Nanotechnology_list.append(0)\n",
    "\n",
    "    if list1[15]>0:\n",
    "        Quantum_Computing_list.append(list1[4])\n",
    "    if list1[15]==0:\n",
    "        Quantum_Computing_list.append(0)\n",
    "\n",
    "df['BigData1'] = pd.Series(bigdata_list1)\n",
    "df['BigData2'] = pd.Series(bigdata_list2)\n",
    "df['Cloud']=pd.Series(cloud_list)\n",
    "df['AI']=pd.Series(AI_list)\n",
    "df['ML']=pd.Series(ML_list)\n",
    "df['Analytics']=pd.Series(Analytics_list)\n",
    "df['Autonomous_vehicles'] = pd.Series(Autonomous_vehicles_list)\n",
    "df['Robotics'] = pd.Series(Robotics_list)\n",
    "df['Augmented_Reality']=pd.Series(Augmented_Reality_list)\n",
    "df['Virtual_Reality']=pd.Series(Virtual_Reality_list)\n",
    "df['D3_Printing']=pd.Series(D3_Printing_list)\n",
    "df['Drones'] = pd.Series(Drones_list)\n",
    "df['Internet_of_Things'] = pd.Series(Internet_of_Things_list)\n",
    "df['Blockchain']=pd.Series(Blockchain_list)\n",
    "df['Nanotechnology']=pd.Series(Nanotechnology_list)\n",
    "df['Quantum_Computing']=pd.Series(Quantum_Computing_list)\n",
    "df.to_csv(\"C:\\Users\\User\\Desktop\\Web Data Analytics\\Project\\WorkDir\\Used_wordv2.csv\")\n",
    "df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": true,
    "editable": true
   },
   "source": [
    "# Extracting Profit Margins"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import urllib2\n",
    "df = pd.read_csv('all companies v4.csv')\n",
    "del df[\"pm2016\"],df[\"pm2015\"],df[\"pm2014\"],df[\"pm2013\"],df[\"roe2015\"],df[\"roe2014\"],df[\"roe2013\"],df[\"roe2016\"]\n",
    "urls = df[\"urls\"].tolist()\n",
    "temp = temp[:start]\n",
    "templist = []\n",
    "if temp.find(\"EE3524\") != -1 and temp.find(\"47C3D3\") != -1:\n",
    "    while temp.find(\"EE3524\") != -1 and temp.find(\"47C3D3\") != -1:\n",
    "        if temp.find(\"EE3524\") < temp.find(\"47C3D3\"):\n",
    "            templist.append(-1)\n",
    "            temp = temp[temp.find(\"EE3524\")+1:]\n",
    "        else:\n",
    "            templist.append(1)\n",
    "            temp = temp[temp.find(\"47C3D3\")+1:]\n",
    "    if temp.find(\"47C3D3\") == -1:\n",
    "        templist = templist + [-1]*(4-len(templist))\n",
    "    else:\n",
    "        templist = templist + [1]*(4-len(templist))\n",
    "elif temp.find(\"EE3524\") == -1:\n",
    "    templist = [1,1,1,1]\n",
    "else:\n",
    "    templist = [-1,-1,-1,-1]\n",
    "\n",
    "for i in range(0,len(pf)):\n",
    "    if templist[i] == -1:\n",
    "        pf[i] = '-' + pf[i]\n",
    "\n",
    "import time\n",
    "from urllib import FancyURLopener  # This is library that helps us create the headless browser\n",
    "from random import choice #This library helps pick a random item from a list\n",
    "\n",
    "user_agents = [\n",
    "    'Mozilla/5.0 (Windows NT 6.1) AppleWebKit/537.36 (KHTML, like Gecko) Chrome/41.0.2228.0 Safari/537.36',\n",
    "    'Opera/9.80 (X11; Linux i686; Ubuntu/14.10) Presto/2.12.388 Version/12.16',\n",
    "    'Mozilla/5.0 (Windows; U; Windows NT 6.1; rv:2.2) Gecko/20110201',\n",
    "    'Mozilla/5.0 (Macintosh; Intel Mac OS X 10_9_3) AppleWebKit/537.75.14 (KHTML, like Gecko) Version/7.0.3 Safari/7046A194A',\n",
    "    'Mozilla/5.0 (Windows NT 10.0; Win64; x64) AppleWebKit/537.36 (KHTML, like Gecko) Chrome/42.0.2311.135 Safari/537.36 Edge/12.246'\n",
    "]\n",
    "\n",
    "\n",
    "pmargin = []\n",
    "for link in urls:\n",
    "    \n",
    "    class MyOpener(FancyURLopener, object):\n",
    "        version = choice(user_agents)\n",
    "    \n",
    "    myopener = MyOpener()\n",
    "    page=myopener.open(link)\n",
    "    \n",
    "    html = page.read()\n",
    "    \n",
    "    html = html[html.find(\"Profit Margin\"):]\n",
    "    temp = html\n",
    "    start = html.find(\"%</td>\\r\\n\")\n",
    "    end = html.find(\"</tr>\\r\\n\\r\\n\")\n",
    "    html = html[start-3:end-35]\n",
    "    \n",
    "    pf = html.split(\"</td>\\r\\n                                <td>\")\n",
    "    \n",
    "    if pf == ['']:\n",
    "        pf = ['','','','']\n",
    "    elif pf[0][0] == \"d\":\n",
    "        pf[0] = pf[0][2:]\n",
    "    elif pf[0][0] == \">\":\n",
    "        pf[0] = pf[0][1:]\n",
    "    else:\n",
    "        pass\n",
    "    \n",
    "    temp = temp[:start]\n",
    "    templist = []\n",
    "    if temp.find(\"EE3524\") != -1 and temp.find(\"47C3D3\") != -1:\n",
    "        while temp.find(\"EE3524\") != -1 and temp.find(\"47C3D3\") != -1:\n",
    "            if temp.find(\"EE3524\") < temp.find(\"47C3D3\"):\n",
    "                templist.append(-1)\n",
    "                temp = temp[temp.find(\"EE3524\")+1:]\n",
    "            else:\n",
    "                templist.append(1)\n",
    "                temp = temp[temp.find(\"47C3D3\")+1:]\n",
    "        if temp.find(\"47C3D3\") == -1:\n",
    "            templist = templist + [-1]*(4-len(templist))\n",
    "        else:\n",
    "            templist = templist + [1]*(4-len(templist))\n",
    "    elif temp.find(\"EE3524\") == -1:\n",
    "        templist = [1,1,1,1]\n",
    "    else:\n",
    "        templist = [-1,-1,-1,-1]    \n",
    "    \n",
    "    for i in range(0,len(pf)):\n",
    "        if templist[i] == -1:\n",
    "            pf[i] = '-' + pf[i] \n",
    "    \n",
    "    pmargin.append(pf)\n",
    "    \n",
    "labels = [\"pm2016\",\"pm2015\",\"pm2014\",\"pm2013\"]\n",
    "profitMargin = pd.DataFrame.from_records(pmargin, columns = labels)\n",
    "df = df.join(profitMargin)\n",
    "df.to_csv('all companies v5.csv',index=False)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": true,
    "editable": true
   },
   "source": [
    "# Return over Equity"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import urllib2\n",
    "df = pd.read_csv('all companies v5.csv')\n",
    "urls = df[\"urls\"].tolist()\n",
    "html = urllib2.urlopen(urls[5]).read()\n",
    "html = html[html.find(\"After Tax ROE\"):]\n",
    "temp = html\n",
    "start = html.find(\"%</td>\\r\\n\")\n",
    "end = html.find(\"</td>\\r\\n                            </tr>\\r\\n\")\n",
    "html = html[start-3:end]\n",
    "pf = html.split(\"</td>\\r\\n                                <td>\")\n",
    "if pf == ['']:\n",
    "    pf = ['','','','']\n",
    "elif pf[0][0] == \"d\":\n",
    "    pf[0] = pf[0][2:]\n",
    "elif pf[0][0] == \">\":\n",
    "    pf[0] = pf[0][1:]\n",
    "else:\n",
    "    pass\n",
    "pf\n",
    "\n",
    "    temp = temp[:start]\n",
    "    templist = []\n",
    "    if temp.find(\"EE3524\") != -1 and temp.find(\"47C3D3\") != -1:\n",
    "        while temp.find(\"EE3524\") != -1 and temp.find(\"47C3D3\") != -1:\n",
    "            if temp.find(\"EE3524\") < temp.find(\"47C3D3\"):\n",
    "                templist.append(-1)\n",
    "                temp = temp[temp.find(\"EE3524\")+1:]\n",
    "            else:\n",
    "                templist.append(1)\n",
    "                temp = temp[temp.find(\"47C3D3\")+1:]\n",
    "        if temp.find(\"47C3D3\") == -1:\n",
    "            templist = templist + [-1]*(4-len(templist))\n",
    "        else:\n",
    "            templist = templist + [1]*(4-len(templist))\n",
    "    elif temp.find(\"EE3524\") == -1:\n",
    "        templist = [1,1,1,1]\n",
    "    else:\n",
    "        templist = [-1,-1,-1,-1]    \n",
    "    \n",
    "    for i in range(0,len(pf)):\n",
    "        if templist[i] == -1:\n",
    "            pf[i] = '-' + pf[i] \n",
    "    pf\n",
    "    \n",
    "import time\n",
    "from urllib import FancyURLopener  # This is library that helps us create the headless browser\n",
    "from random import choice #This library helps pick a random item from a list\n",
    "\n",
    "user_agents = [\n",
    "    'Mozilla/5.0 (Windows NT 6.1) AppleWebKit/537.36 (KHTML, like Gecko) Chrome/41.0.2228.0 Safari/537.36',\n",
    "    'Opera/9.80 (X11; Linux i686; Ubuntu/14.10) Presto/2.12.388 Version/12.16',\n",
    "    'Mozilla/5.0 (Windows; U; Windows NT 6.1; rv:2.2) Gecko/20110201',\n",
    "    'Mozilla/5.0 (Macintosh; Intel Mac OS X 10_9_3) AppleWebKit/537.75.14 (KHTML, like Gecko) Version/7.0.3 Safari/7046A194A',\n",
    "    'Mozilla/5.0 (Windows NT 10.0; Win64; x64) AppleWebKit/537.36 (KHTML, like Gecko) Chrome/42.0.2311.135 Safari/537.36 Edge/12.246'\n",
    "]\n",
    "\n",
    "roe = []\n",
    "for link in urls:\n",
    "    \n",
    "    class MyOpener(FancyURLopener, object):\n",
    "        version = choice(user_agents)\n",
    "    \n",
    "    myopener = MyOpener()\n",
    "    page=myopener.open(link)\n",
    "    \n",
    "    html = page.read()\n",
    "    \n",
    "    html = html[html.find(\"After Tax ROE\"):]\n",
    "    temp = html\n",
    "    start = html.find(\"%</td>\\r\\n\")\n",
    "    end = html.find(\"</td>\\r\\n                            </tr>\\r\\n\")\n",
    "    html = html[start-3:end]\n",
    "    \n",
    "    pf = html.split(\"</td>\\r\\n                                <td>\")\n",
    "    \n",
    "    if pf == ['']:\n",
    "        pf = ['','','','']\n",
    "    elif pf[0][0] == \"d\":\n",
    "        pf[0] = pf[0][2:]\n",
    "    elif pf[0][0] == \">\":\n",
    "        pf[0] = pf[0][1:]\n",
    "    else:\n",
    "        pass\n",
    "    \n",
    "    temp = temp[:start]\n",
    "    templist = []\n",
    "    if temp.find(\"EE3524\") != -1 and temp.find(\"47C3D3\") != -1:\n",
    "        while temp.find(\"EE3524\") != -1 and temp.find(\"47C3D3\") != -1:\n",
    "            if temp.find(\"EE3524\") < temp.find(\"47C3D3\"):\n",
    "                templist.append(-1)\n",
    "                temp = temp[temp.find(\"EE3524\")+1:]\n",
    "            else:\n",
    "                templist.append(1)\n",
    "                temp = temp[temp.find(\"47C3D3\")+1:]\n",
    "        if temp.find(\"47C3D3\") == -1:\n",
    "            templist = templist + [-1]*(4-len(templist))\n",
    "        else:\n",
    "            templist = templist + [1]*(4-len(templist))\n",
    "    elif temp.find(\"EE3524\") == -1:\n",
    "        templist = [1,1,1,1]\n",
    "    else:\n",
    "        templist = [-1,-1,-1,-1]    \n",
    "    \n",
    "    for i in range(0,len(pf)):\n",
    "        if templist[i] == -1:\n",
    "            pf[i] = '-' + pf[i] \n",
    "    \n",
    "    roe.append(pf)\n",
    "    \n",
    "labels = [\"roe2016\",\"roe2015\",\"roe2014\",\"roe2013\"]\n",
    "aftertaxroe = pd.DataFrame.from_records(roe, columns = labels)\n",
    "df = df.join(aftertaxroe)\n",
    "df.to_csv('all companies v6.csv',index=False)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": true,
    "editable": true
   },
   "source": [
    "# Stock Prices"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "#import urllib2 for python 2\n",
    "import urllib3\n",
    "import bs4 as bs\n",
    "from bs4 import SoupStrainer\n",
    "import codecs\n",
    "import pandas as pd\n",
    "companies = pd.read_csv(\"C:\\\\Users\\\\carlvader\\\\Downloads\\\\all companies v4.csv\", encoding='latin1')\n",
    "companies.head()\n",
    "import time\n",
    "# for python 2 run the following command\n",
    "# from urllib2 import FancyURLopener\n",
    "from urllib.request import FancyURLopener  # This is library that helps us create the headless browser\n",
    "from random import choice #This library helps pick a random item from a list\n",
    "\n",
    "user_agents = [\n",
    "    'Mozilla/5.0 (Windows NT 6.1) AppleWebKit/537.36 (KHTML, like Gecko) Chrome/41.0.2228.0 Safari/537.36',\n",
    "    'Opera/9.80 (X11; Linux i686; Ubuntu/14.10) Presto/2.12.388 Version/12.16',\n",
    "    'Mozilla/5.0 (Windows; U; Windows NT 6.1; rv:2.2) Gecko/20110201',\n",
    "    'Mozilla/5.0 (Macintosh; Intel Mac OS X 10_9_3) AppleWebKit/537.75.14 (KHTML, like Gecko) Version/7.0.3 Safari/7046A194A',\n",
    "    'Mozilla/5.0 (Windows NT 10.0; Win64; x64) AppleWebKit/537.36 (KHTML, like Gecko) Chrome/42.0.2311.135 Safari/537.36 Edge/12.246'\n",
    "]\n",
    "\n",
    "class MyOpener(FancyURLopener, object):\n",
    "    version = choice(user_agents)\n",
    "\n",
    "urls=[]\n",
    "symbols=companies[\"Symbol\"].tolist()\n",
    "for i in symbols:\n",
    "    urls.append('https://finance.yahoo.com/quote/' + i + '/history?period1=1353992400&period2=1511758800&interval=1mo&filter=history&frequency=1mo')       \n",
    "\n",
    "import datetime\n",
    "date=[]\n",
    "closestock=[]\n",
    "final=[]\n",
    "dates=['Jan 01, 2015','Jan 01, 2016','Jan 01, 2017']\n",
    "\n",
    "for i in urls:\n",
    "    myopener = MyOpener()\n",
    "    page=myopener.open(i)\n",
    "    inthtml1 = page.read()\n",
    "    html1=str(inthtml1)\n",
    "    for j in dates:\n",
    "        date.append(j)\n",
    "        \n",
    "        ## company name\n",
    "        start=html1.find('<h1 class')\n",
    "        if start!=-1:\n",
    "            remaining=html1[start:]\n",
    "            start=remaining.find('>')\n",
    "            remaining2=remaining[start+1:]\n",
    "            end=remaining2.find('</h1>')\n",
    "            remaining3=remaining2[:end]\n",
    "            final.append(remaining3)\n",
    "\n",
    "            ## closing stock price\n",
    "            start=html1.find(j)\n",
    "            if start!=-1:\n",
    "                remaining1=html1[start-15:]\n",
    "                end=remaining1.find(\"</tr>\")\n",
    "                html2=remaining1[:end]\n",
    "                html=bs.BeautifulSoup(html2, 'lxml')\n",
    "                x=html.find_all('span')[4].getText()\n",
    "                closestock.append(x)\n",
    "            else:\n",
    "                closestock.append('N/A')\n",
    "            \n",
    "        else:\n",
    "            \n",
    "            start=html1.find('Symbols similar to')\n",
    "            remaining=html1[start+25:]\n",
    "            end=remaining.find('</span>')\n",
    "            remaining1=remaining[:end-6]\n",
    "            final.append(remaining1)\n",
    "            closestock.append('N/A')\n",
    "          "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "df=pd.DataFrame({'companyname':final,'date':date,'gf':closestock})"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
